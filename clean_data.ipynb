{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ§¹ Nettoyage des DonnÃ©es â€” Morocco Student Data Pool\n",
                "\n",
                "Ce notebook effectue le nettoyage du dataset **Morocco_Student_Data_Pool.csv**.\n",
                "\n",
                "### Pipeline du projet :\n",
                "1. **`analyze_data.ipynb`** â†’ AperÃ§u initial des donnÃ©es brutes\n",
                "2. **`clean_data.ipynb`** â† (ce notebook) Nettoyage et prÃ©paration\n",
                "3. **`EDA_AdvancedØ§.ipynb`** â†’ Analyse exploratoire avancÃ©e\n",
                "\n",
                "### Ã‰tapes de nettoyage :\n",
                "1. Chargement et aperÃ§u initial\n",
                "2. Correction du dÃ©calage de colonnes\n",
                "3. Suppression des colonnes entiÃ¨rement vides\n",
                "4. Imputation des valeurs manquantes (moyenne / mÃ©diane / mode)\n",
                "5. Conversion des dates\n",
                "6. Normalisation des colonnes textuelles (hors dates et IDs)\n",
                "7. Validation des colonnes numÃ©riques (notes, taux)\n",
                "8. DÃ©tection et traitement des outliers\n",
                "9. RÃ©sumÃ© et export\n",
                "\n",
                "> **âš ï¸ Principe clÃ©** : Les colonnes avec des valeurs manquantes sont imputÃ©es par la **moyenne** (distribution symÃ©trique) ou la **mÃ©diane** (distribution asymÃ©trique), et non supprimÃ©es, car chaque variable peut contenir de l'information utile pour la prÃ©diction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… BibliothÃ¨ques importÃ©es\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"âœ… BibliothÃ¨ques importÃ©es\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Chargement des donnÃ©es"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“Š Dataset chargÃ©\n",
                        "   Lignes : 10,000  |  Colonnes : 286\n",
                        "   Valeurs manquantes : 204,699 (7.16%)\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv('Morocco_Student_Data_Pool.csv', low_memory=False)\n",
                "\n",
                "shape_avant = df.shape\n",
                "missing_avant = df.isnull().sum().sum()\n",
                "\n",
                "print(f\"ğŸ“Š Dataset chargÃ©\")\n",
                "print(f\"   Lignes : {df.shape[0]:,}  |  Colonnes : {df.shape[1]}\")\n",
                "print(f\"   Valeurs manquantes : {missing_avant:,} ({missing_avant / (df.shape[0] * df.shape[1]) * 100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Correction du dÃ©calage de colonnes\n",
                "\n",
                "Le CSV brut contient un **dÃ©calage d'une colonne** vers la gauche dans les derniÃ¨res colonnes (aprÃ¨s `performance_cible`).  \n",
                "Par exemple, `date_collecte` contient en rÃ©alitÃ© les codes collecteurs (`COL008`), et les vraies dates se trouvent dans `intervention_necessaire`.\n",
                "\n",
                "On corrige ce dÃ©calage en rÃ©alignant les donnÃ©es vers leurs bonnes colonnes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âš ï¸ DÃ©calage de colonnes dÃ©tectÃ© ! Correction en cours...\n",
                        "âœ… Colonnes rÃ©alignÃ©es :\n",
                        "   date_collecte[0] = 2026-01-15\n",
                        "   id_collecteur[0] = COL008\n",
                        "   intervention_necessaire[0] = Oui\n"
                    ]
                }
            ],
            "source": [
                "shifted_cols = [\n",
                "    'probabilite_reussite',    # contient â†’ niveau_risque\n",
                "    'niveau_risque',           # contient â†’ intervention_necessaire\n",
                "    'intervention_necessaire', # contient â†’ date_collecte\n",
                "    'date_collecte',           # contient â†’ id_collecteur\n",
                "    'id_collecteur',           # contient â†’ statut_verification\n",
                "    'statut_verification',     # contient â†’ date_mise_a_jour\n",
                "]\n",
                "\n",
                "cols_exist = all(c in df.columns for c in shifted_cols)\n",
                "if cols_exist and str(df['date_collecte'].iloc[0]).startswith('COL'):\n",
                "    print(\"âš ï¸ DÃ©calage de colonnes dÃ©tectÃ© ! Correction en cours...\")\n",
                "    \n",
                "    saved = {col: df[col].copy() for col in shifted_cols}\n",
                "    \n",
                "    df['niveau_risque'] = saved['probabilite_reussite']\n",
                "    df['intervention_necessaire'] = saved['niveau_risque']\n",
                "    df['date_collecte'] = saved['intervention_necessaire']\n",
                "    df['id_collecteur'] = saved['date_collecte']\n",
                "    df['statut_verification'] = saved['id_collecteur']\n",
                "    df['probabilite_reussite'] = np.nan  # donnÃ©es d'origine perdues\n",
                "    \n",
                "    print(\"âœ… Colonnes rÃ©alignÃ©es :\")\n",
                "    print(f\"   date_collecte[0] = {df['date_collecte'].iloc[0]}\")\n",
                "    print(f\"   id_collecteur[0] = {df['id_collecteur'].iloc[0]}\")\n",
                "    print(f\"   intervention_necessaire[0] = {df['intervention_necessaire'].iloc[0]}\")\n",
                "else:\n",
                "    print(\"âœ… Pas de dÃ©calage dÃ©tectÃ© â€” colonnes correctes.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Suppression des colonnes entiÃ¨rement vides (100% NaN)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ—‘ï¸ 18 colonnes avec 100% de NaN supprimÃ©es :\n",
                        "   â€¢ type_handicap\n",
                        "   â€¢ economie_s1\n",
                        "   â€¢ economie_s2\n",
                        "   â€¢ economie_annuel\n",
                        "   â€¢ comptabilite_s1\n",
                        "   â€¢ comptabilite_s2\n",
                        "   â€¢ comptabilite_annuel\n",
                        "   â€¢ gestion_s1\n",
                        "   â€¢ gestion_s2\n",
                        "   â€¢ gestion_annuel\n",
                        "   â€¢ note_examen_regional\n",
                        "   â€¢ note_examen_national\n",
                        "   â€¢ note_controle_continu\n",
                        "   â€¢ note_finale_bac\n",
                        "   â€¢ mention_bac\n",
                        "   â€¢ probabilite_reussite\n",
                        "   â€¢ date_mise_a_jour\n",
                        "   â€¢ remarques\n",
                        "\n",
                        "   Nouvelle forme : (10000, 268)\n"
                    ]
                }
            ],
            "source": [
                "missing_percent = df.isnull().mean()\n",
                "cols_100_missing = missing_percent[missing_percent == 1.0].index.tolist()\n",
                "\n",
                "print(f\"ğŸ—‘ï¸ {len(cols_100_missing)} colonnes avec 100% de NaN supprimÃ©es :\")\n",
                "for col in cols_100_missing:\n",
                "    print(f\"   â€¢ {col}\")\n",
                "\n",
                "df.drop(columns=cols_100_missing, inplace=True)\n",
                "print(f\"\\n   Nouvelle forme : {df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Imputation des valeurs manquantes\n",
                "\n",
                "**StratÃ©gie :**\n",
                "- **NumÃ©riques** : MÃ©diane si |skewness| > 1, sinon Moyenne\n",
                "- **CatÃ©gorielles** : Valeur par dÃ©faut sÃ©mantique ou Mode"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ“‹ 9 colonnes avec des valeurs manquantes :\n",
                        "\n",
                        "Colonne                           NaN        % Type         StratÃ©gie\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "pays_cible                       8344    83.4% object       Mode / Valeur par dÃ©faut âš ï¸\n",
                        "etablissement_precedent          5925    59.2% object       Mode / Valeur par dÃ©faut\n",
                        "matieres_soutien                 4813    48.1% object       Mode / Valeur par dÃ©faut\n",
                        "annees_redoublees                4537    45.4% object       Mode / Valeur par dÃ©faut\n",
                        "niveau_allemand                  2953    29.5% object       Mode / Valeur par dÃ©faut\n",
                        "type_art                         2263    22.6% object       Mode / Valeur par dÃ©faut\n",
                        "type_travail                     2239    22.4% object       Mode / Valeur par dÃ©faut\n",
                        "type_maladie                     2204    22.0% object       Mode / Valeur par dÃ©faut\n",
                        "type_sport                       1421    14.2% object       Mode / Valeur par dÃ©faut\n"
                    ]
                }
            ],
            "source": [
                "# RÃ©sumÃ© des colonnes avec NaN\n",
                "missing_cols = df.isnull().sum()\n",
                "missing_cols = missing_cols[missing_cols > 0].sort_values(ascending=False)\n",
                "\n",
                "print(f\"ğŸ“‹ {len(missing_cols)} colonnes avec des valeurs manquantes :\\n\")\n",
                "print(f\"{'Colonne':<30} {'NaN':>6} {'%':>8} {'Type':<12} {'StratÃ©gie'}\")\n",
                "print('â”€' * 80)\n",
                "\n",
                "for col in missing_cols.index:\n",
                "    n_miss = missing_cols[col]\n",
                "    pct = n_miss / len(df) * 100\n",
                "    dtype = str(df[col].dtype)\n",
                "    if df[col].dtype in ['float64', 'int64']:\n",
                "        skew = df[col].skew()\n",
                "        strategy = f\"MÃ©diane (skew={skew:.2f})\" if abs(skew) > 1 else f\"Moyenne (skew={skew:.2f})\"\n",
                "    else:\n",
                "        strategy = \"Mode / Valeur par dÃ©faut\"\n",
                "    flag = \" âš ï¸\" if pct > 80 else \"\"\n",
                "    print(f\"{col:<30} {n_miss:>6} {pct:>7.1f}% {dtype:<12} {strategy}{flag}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Aucune colonne numÃ©rique Ã  imputer.\n"
                    ]
                }
            ],
            "source": [
                "# --- Imputation NUMÃ‰RIQUES ---\n",
                "numeric_missing = [col for col in missing_cols.index if df[col].dtype in ['float64', 'int64']]\n",
                "\n",
                "imputation_log = []\n",
                "for col in numeric_missing:\n",
                "    skewness = df[col].skew()\n",
                "    if abs(skewness) > 1:\n",
                "        fill_value = df[col].median()\n",
                "        method = 'MÃ©diane'\n",
                "    else:\n",
                "        fill_value = df[col].mean()\n",
                "        method = 'Moyenne'\n",
                "    \n",
                "    n_filled = df[col].isnull().sum()\n",
                "    df[col] = df[col].fillna(fill_value)\n",
                "    imputation_log.append({\n",
                "        'Colonne': col, 'MÃ©thode': method,\n",
                "        'Valeur': round(fill_value, 2), 'Skewness': round(skewness, 2),\n",
                "        'NaN remplis': n_filled\n",
                "    })\n",
                "\n",
                "if imputation_log:\n",
                "    print(f\"âœ… {len(numeric_missing)} colonnes numÃ©riques imputÃ©es :\\n\")\n",
                "    print(pd.DataFrame(imputation_log).to_string(index=False))\n",
                "else:\n",
                "    print(\"Aucune colonne numÃ©rique Ã  imputer.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… 9 colonnes catÃ©gorielles imputÃ©es :\n",
                        "\n",
                        "                Colonne           MÃ©thode          Valeur  NaN remplis\n",
                        "             pays_cible Valeur par dÃ©faut    Non spÃ©cifiÃ©         8344\n",
                        "etablissement_precedent              Mode Lycee Ibn Rochd         5925\n",
                        "       matieres_soutien Valeur par dÃ©faut           Aucun         4813\n",
                        "      annees_redoublees              Mode       2022-2023         4537\n",
                        "        niveau_allemand Valeur par dÃ©faut      Non Ã©tudiÃ©         2953\n",
                        "               type_art Valeur par dÃ©faut           Aucun         2263\n",
                        "           type_travail Valeur par dÃ©faut           Aucun         2239\n",
                        "           type_maladie Valeur par dÃ©faut          Aucune         2204\n",
                        "             type_sport Valeur par dÃ©faut           Aucun         1421\n"
                    ]
                }
            ],
            "source": [
                "# --- Imputation CATÃ‰GORIELLES ---\n",
                "cat_missing = [col for col in missing_cols.index if df[col].dtype == 'object']\n",
                "\n",
                "default_values = {\n",
                "    'type_sport': 'Aucun', 'type_art': 'Aucun',\n",
                "    'matieres_soutien': 'Aucun', 'type_maladie': 'Aucune',\n",
                "    'type_travail': 'Aucun', 'pays_cible': 'Non spÃ©cifiÃ©',\n",
                "    'niveau_allemand': 'Non Ã©tudiÃ©'\n",
                "}\n",
                "\n",
                "cat_log = []\n",
                "for col in cat_missing:\n",
                "    n_filled = df[col].isnull().sum()\n",
                "    if col in default_values:\n",
                "        fill_value = default_values[col]\n",
                "        method = 'Valeur par dÃ©faut'\n",
                "    else:\n",
                "        fill_value = df[col].mode()[0] if not df[col].mode().empty else 'Inconnu'\n",
                "        method = 'Mode'\n",
                "    df[col] = df[col].fillna(fill_value)\n",
                "    cat_log.append({'Colonne': col, 'MÃ©thode': method, 'Valeur': fill_value, 'NaN remplis': n_filled})\n",
                "\n",
                "if cat_log:\n",
                "    print(f\"âœ… {len(cat_missing)} colonnes catÃ©gorielles imputÃ©es :\\n\")\n",
                "    print(pd.DataFrame(cat_log).to_string(index=False))\n",
                "else:\n",
                "    print(\"Aucune colonne catÃ©gorielle Ã  imputer.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ” Valeurs manquantes restantes : 0\n",
                        "   âœ… Imputation complÃ¨te â€” aucune valeur manquante !\n"
                    ]
                }
            ],
            "source": [
                "# VÃ©rification\n",
                "remaining_na = df.isnull().sum().sum()\n",
                "print(f\"ğŸ” Valeurs manquantes restantes : {remaining_na}\")\n",
                "if remaining_na == 0:\n",
                "    print(\"   âœ… Imputation complÃ¨te â€” aucune valeur manquante !\")\n",
                "else:\n",
                "    remaining = df.isnull().sum()\n",
                "    print(remaining[remaining > 0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Conversion des dates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   date_naissance : âœ… OK\n",
                        "   date_collecte : âœ… OK\n"
                    ]
                }
            ],
            "source": [
                "date_cols = ['date_naissance', 'date_collecte']\n",
                "for col in date_cols:\n",
                "    if col in df.columns:\n",
                "        df[col] = pd.to_datetime(df[col], format='%Y-%m-%d', errors='coerce')\n",
                "        n_nat = df[col].isna().sum()\n",
                "        status = f'âš ï¸ {n_nat} NaT' if n_nat > 0 else 'âœ… OK'\n",
                "        print(f\"   {col} : {status}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Normalisation des colonnes textuelles\n",
                "\n",
                "**âš ï¸ Important** : Les colonnes de dates et d'identifiants sont exclues de la normalisation `title case`  \n",
                "pour Ã©viter de casser les formats (ex: `STU00001` â†’ `Stu00001`, dates â†’ illisibles)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… 167 colonnes textuelles normalisÃ©es (strip + title case)\n",
                        "âœ… 3 colonnes prÃ©servÃ©es (strip uniquement) : ['id_etudiant', 'code_massar', 'id_collecteur']\n"
                    ]
                }
            ],
            "source": [
                "# Colonnes Ã  exclure du title case (dates, IDs, codes)\n",
                "exclude_from_title = ['date_naissance', 'date_collecte', 'id_etudiant', 'code_massar', 'id_collecteur']\n",
                "\n",
                "text_cols = df.select_dtypes(include='object').columns\n",
                "normalized_count = 0\n",
                "stripped_count = 0\n",
                "\n",
                "for col in text_cols:\n",
                "    if col in exclude_from_title:\n",
                "        df[col] = df[col].astype(str).str.strip()\n",
                "        stripped_count += 1\n",
                "    else:\n",
                "        df[col] = df[col].astype(str).str.strip().str.title()\n",
                "        normalized_count += 1\n",
                "\n",
                "print(f\"âœ… {normalized_count} colonnes textuelles normalisÃ©es (strip + title case)\")\n",
                "print(f\"âœ… {stripped_count} colonnes prÃ©servÃ©es (strip uniquement) : {[c for c in exclude_from_title if c in text_cols]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Validation des colonnes numÃ©riques\n",
                "\n",
                "- **Notes** â†’ [0, 20] â€” avec dÃ©tection automatique de l'Ã©chelle (0-100 â†’ converti en 0-20)\n",
                "- **Taux** â†’ [0, 100]\n",
                "- **Ã‚ge** â†’ [15, 25]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   ğŸ”„ rang_s1 : 5329 valeurs converties (Ã©chelle 0-100 â†’ 0-20)\n",
                        "   ğŸ”„ rang_s2 : 5352 valeurs converties (Ã©chelle 0-100 â†’ 0-20)\n",
                        "   ğŸ”„ rang_annuel : 5329 valeurs converties (Ã©chelle 0-100 â†’ 0-20)\n",
                        "ğŸ“ 40 colonnes de notes â†’ 16010 converties, 0 clippÃ©es dans [0,20]\n",
                        "ğŸ“Š 4 colonnes de taux â†’ 0 valeurs clippÃ©es dans [0,100]\n",
                        "ğŸ‚ Ã‚ge â†’ 0 valeurs clippÃ©es dans [15,25]\n"
                    ]
                }
            ],
            "source": [
                "# Notes â€” avec dÃ©tection d'Ã©chelle\n",
                "grade_cols = [c for c in df.columns if any(x in c for x in ['_s1', '_s2', '_annuel', 'note_', 'moyenne'])]\n",
                "for col in grade_cols:\n",
                "    if col in df.columns:\n",
                "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
                "\n",
                "clipped_grades = 0\n",
                "scaled_grades = 0\n",
                "for col in grade_cols:\n",
                "    if col in df.columns:\n",
                "        values_above_20 = (df[col] > 20).sum()\n",
                "        total_non_nan = df[col].notna().sum()\n",
                "        if total_non_nan > 0 and values_above_20 / total_non_nan > 0.10:\n",
                "            # Ã‰chelle 0-100 dÃ©tectÃ©e â†’ convertir en 0-20\n",
                "            scaled_grades += values_above_20\n",
                "            df[col] = df[col] / 5.0\n",
                "            df[col] = df[col].clip(0, 20)\n",
                "            print(f\"   ğŸ”„ {col} : {values_above_20} valeurs converties (Ã©chelle 0-100 â†’ 0-20)\")\n",
                "        else:\n",
                "            out = ((df[col] < 0) | (df[col] > 20)).sum()\n",
                "            if out > 0:\n",
                "                clipped_grades += out\n",
                "                df[col] = df[col].clip(0, 20)\n",
                "\n",
                "print(f\"ğŸ“ {len(grade_cols)} colonnes de notes â†’ {scaled_grades} converties, {clipped_grades} clippÃ©es dans [0,20]\")\n",
                "\n",
                "# Taux\n",
                "taux_cols = [c for c in df.columns if 'taux' in c]\n",
                "clipped_taux = 0\n",
                "for col in taux_cols:\n",
                "    if col in df.columns:\n",
                "        out = ((df[col] < 0) | (df[col] > 100)).sum()\n",
                "        if out > 0:\n",
                "            clipped_taux += out\n",
                "            df[col] = df[col].clip(0, 100)\n",
                "print(f\"ğŸ“Š {len(taux_cols)} colonnes de taux â†’ {clipped_taux} valeurs clippÃ©es dans [0,100]\")\n",
                "\n",
                "# Ã‚ge\n",
                "if 'age' in df.columns:\n",
                "    age_out = ((df['age'] < 15) | (df['age'] > 25)).sum()\n",
                "    df['age'] = df['age'].clip(15, 25)\n",
                "    print(f\"ğŸ‚ Ã‚ge â†’ {age_out} valeurs clippÃ©es dans [15,25]\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. DÃ©tection et traitement des outliers (IQR)\n",
                "\n",
                "**âš ï¸ Note** : `nombre_freres_soeurs` est traitÃ© avec un seuil adaptÃ© au contexte marocain (max=10)  \n",
                "au lieu du clipping IQR automatique (qui donnerait max=4, trop restrictif)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ” Outliers clippÃ©s :\n",
                        "\n",
                        "            Colonne         Bornes  Outliers clippÃ©s MÃ©thode\n",
                        "revenu_mensuel_pere [-6241, 22705]               241     IQR\n",
                        "revenu_mensuel_mere [-5736, 16609]               205     IQR\n",
                        "    revenu_familial [-6020, 32880]               214     IQR\n"
                    ]
                }
            ],
            "source": [
                "MAX_FRERES_SOEURS = 10\n",
                "EXCLUDE_FROM_IQR = ['nombre_freres_soeurs']\n",
                "\n",
                "outlier_cols = [c for c in df.columns if any(x in c for x in ['revenu', 'experience', 'nombre_freres'])]\n",
                "outlier_cols = [c for c in outlier_cols if df[c].dtype in ['float64', 'int64']]\n",
                "\n",
                "outlier_report = []\n",
                "for col in outlier_cols:\n",
                "    if col in EXCLUDE_FROM_IQR:\n",
                "        n_out = (df[col] > MAX_FRERES_SOEURS).sum()\n",
                "        if n_out > 0:\n",
                "            df[col] = df[col].clip(0, MAX_FRERES_SOEURS)\n",
                "            outlier_report.append({\n",
                "                'Colonne': col, 'Bornes': f'[0, {MAX_FRERES_SOEURS}]',\n",
                "                'Outliers clippÃ©s': n_out, 'MÃ©thode': 'Seuil domaine'\n",
                "            })\n",
                "    else:\n",
                "        Q1 = df[col].quantile(0.25)\n",
                "        Q3 = df[col].quantile(0.75)\n",
                "        IQR = Q3 - Q1\n",
                "        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
                "        n_out = ((df[col] < lower) | (df[col] > upper)).sum()\n",
                "        if n_out > 0:\n",
                "            df[col] = df[col].clip(lower, upper)\n",
                "            outlier_report.append({\n",
                "                'Colonne': col, 'Bornes': f'[{lower:.0f}, {upper:.0f}]',\n",
                "                'Outliers clippÃ©s': n_out, 'MÃ©thode': 'IQR'\n",
                "            })\n",
                "\n",
                "if outlier_report:\n",
                "    print(f\"ğŸ” Outliers clippÃ©s :\\n\")\n",
                "    print(pd.DataFrame(outlier_report).to_string(index=False))\n",
                "else:\n",
                "    print(\"Aucun outlier dÃ©tectÃ©.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. RÃ©sumÃ© et export"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=======================================================\n",
                        "ğŸ“Š RÃ‰SUMÃ‰ DES TRANSFORMATIONS\n",
                        "=======================================================\n",
                        "                                 AVANT        APRÃˆS\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "Lignes                           10000        10000\n",
                        "Colonnes                           286          268\n",
                        "Colonnes supprimÃ©es                              18\n",
                        "Valeurs manquantes              204699            0\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                }
            ],
            "source": [
                "shape_apres = df.shape\n",
                "missing_apres = df.isnull().sum().sum()\n",
                "\n",
                "print(\"=\" * 55)\n",
                "print(\"ğŸ“Š RÃ‰SUMÃ‰ DES TRANSFORMATIONS\")\n",
                "print(\"=\" * 55)\n",
                "print(f\"{'':<25} {'AVANT':>12} {'APRÃˆS':>12}\")\n",
                "print(f\"{'â”€' * 50}\")\n",
                "print(f\"{'Lignes':<25} {shape_avant[0]:>12} {shape_apres[0]:>12}\")\n",
                "print(f\"{'Colonnes':<25} {shape_avant[1]:>12} {shape_apres[1]:>12}\")\n",
                "print(f\"{'Colonnes supprimÃ©es':<25} {'':>12} {shape_avant[1] - shape_apres[1]:>12}\")\n",
                "print(f\"{'Valeurs manquantes':<25} {missing_avant:>12} {missing_apres:>12}\")\n",
                "print(f\"{'â”€' * 50}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ’¾ Dataset nettoyÃ© sauvegardÃ© : Morocco_Student_Data_Cleaned.csv\n",
                        "   Taille : 10,000 Ã— 268 colonnes\n",
                        "   NaN restants : 0\n",
                        "\n",
                        "â¡ï¸  Prochaine Ã©tape : exÃ©cuter EDA_AdvancedØ§.ipynb\n"
                    ]
                }
            ],
            "source": [
                "# Export\n",
                "output_file = 'Morocco_Student_Data_Cleaned.csv'\n",
                "df.to_csv(output_file, index=False)\n",
                "\n",
                "print(f\"ğŸ’¾ Dataset nettoyÃ© sauvegardÃ© : {output_file}\")\n",
                "print(f\"   Taille : {df.shape[0]:,} Ã— {df.shape[1]} colonnes\")\n",
                "print(f\"   NaN restants : {df.isnull().sum().sum()}\")\n",
                "print(f\"\\nâ¡ï¸  Prochaine Ã©tape : exÃ©cuter EDA_AdvancedØ§.ipynb\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
